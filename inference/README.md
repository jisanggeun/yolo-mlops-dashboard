# Inference Server

## ğŸ“Œ Overview
YOLO ëª¨ë¸ì„ TensorRTë¡œ ìµœì í™”í•˜ì—¬ ì¶”ë¡ í•˜ëŠ” ì„œë²„ 
(Jetson Orin Nanoìš©)

## ğŸ“ Structure
```
inference/
â”œâ”€â”€ main.py         # FastAPI ì¶”ë¡  ì„œë²„
â”œâ”€â”€ requirements.txt  # ì°¸ê³ ìš© Dependency list
â”œâ”€â”€ Dockerfile      # Jetsonìš© Dockerfile
â””â”€â”€ README.md
```

## ğŸš€ Run (Jetson)
```bash
docker build -t yolo-inference .
docker run -d --runtime nvidia -p 8001:8001 yolo-inference
```

## ğŸ”§ TensorRT ìë™ ë³€í™˜
- ì²« ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ `.pt` â†’ `.engine` ë³€í™˜ (5~10ë¶„)
- ì´í›„ ì‹¤í–‰ ì‹œ `.engine` íŒŒì¼ ë°”ë¡œ ë¡œë“œ (ëª‡ ì´ˆ)

## ğŸ“¡ API Endpoints
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | /health | ì„œë²„ ìƒíƒœ í™•ì¸ |
| POST | /predict | ì´ë¯¸ì§€ ì¶”ë¡  (ì‹œê°í™” í¬í•¨) |
| GET | /models | í˜„ì¬ ëª¨ë¸ ì •ë³´ |

## ğŸ“¤ Response Example
```json
{
  "detections": [
    {
      "class": 0,
      "class_name": "person",
      "confidence": 0.85,
      "bbox": [100, 150, 300, 400]
    }
  ],
  "image_base64": "base64 encoded image..."
}
```